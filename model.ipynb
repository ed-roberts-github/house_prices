{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, Lasso, LassoCV, LassoLarsCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "I will begin by using the knowledge I gained in my EDA to remove outliers and drop irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv', index_col=0)\n",
    "\n",
    "df_dropped = df_all.drop(['PoolQC', 'MiscFeature', 'Alley'], axis=1)\n",
    "df = df_dropped[[\n",
    "       'OverallQual', \n",
    "       'Neighborhood', \n",
    "       'GarageArea', \n",
    "       'GrLivArea', \n",
    "       'YearBuilt',\n",
    "       'TotalBsmtSF', \n",
    "       'LotArea', \n",
    "       'BsmtQual', \n",
    "       'ExterQual',\n",
    "       'KitchenQual', \n",
    "       '1stFlrSF', \n",
    "       'MSSubClass', \n",
    "       'YearRemodAdd',\n",
    "       'FullBath',\n",
    "       'GarageFinish', \n",
    "       'GarageYrBlt', \n",
    "       'LotFrontage', \n",
    "       'FireplaceQu',\n",
    "       'TotRmsAbvGrd', \n",
    "       'SalePrice'\n",
    "       ]].copy()\n",
    "df = df.drop(df[(df['SalePrice']<300000) & (df['GrLivArea'] > 4000)].index)\n",
    "\n",
    "\n",
    "y = df.pop('SalePrice')\n",
    "log_y = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "One could argue there is little need for a pipeline with a relatively simple model, however it is good pratice beacuse it reduces data leakage in cross validation and allows for easy experimentation with models and preprocessing methods.\n",
    "\n",
    "Remember a column transformer can be used to transform different columns but it doesn't link the transforms togther. So if you need to apply to transformations to one column you need to put them in another pipeline then put that pipeline in the column transformer, as I've done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to just use multivariate imputer for this I think\n",
    "# def custom_imputer(df):\n",
    "#     df['LotFrontage'] = df.groupby(by='Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "#     return df\n",
    "# custom_imputer_transformer = FunctionTransformer(func=custom_imputer, validate=False)\n",
    "\n",
    "def log_scaler(df):\n",
    "    df['GrLivArea'] = np.log(df['GrLivArea'])\n",
    "    return df\n",
    "\n",
    "log_transformer = FunctionTransformer(func=log_scaler, validate=False)\n",
    "\n",
    "# Orindal encoding setup\n",
    "ordinal_features = [\n",
    "                    'GarageFinish',\n",
    "                    'BsmtQual',\n",
    "                    'ExterQual',\n",
    "                    'KitchenQual', \n",
    "                    'FireplaceQu'\n",
    "                    ]\n",
    "five_lvls = ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "garage_lvls = ['None', 'Unf', 'RFn', 'Fin']\n",
    "\n",
    "\n",
    "# Target encoding\n",
    "target_enc_features = ['Neighborhood']\n",
    "\n",
    "# Onehot encoding setup\n",
    "onehot_features = ['MSSubClass','Neighborhood']\n",
    "\n",
    "# Features to log scale\n",
    "log_features = ['GrLivArea']\n",
    "\n",
    "\n",
    "preprocessPipe1 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('encoder', OrdinalEncoder(categories=[garage_lvls,five_lvls,five_lvls,five_lvls,five_lvls], \n",
    "                                        handle_unknown='error',\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Pipe1', preprocessPipe1, ordinal_features),\n",
    "        ('MedianImputer', SimpleImputer(strategy='median'), ['LotFrontage']),\n",
    "        ('imputeGaragerYrBlt', SimpleImputer(strategy='constant', fill_value=0), ['GarageYrBlt']),\n",
    "        ('log_scaler', log_transformer, log_features),\n",
    "        # ('targetEncoder', MEstimateEncoder( m=.06), target_enc_features),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), onehot_features),\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking everything is working with a quick cheeky Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSLE in SalePrice is : \n",
      "0.1457633993011705\n"
     ]
    }
   ],
   "source": [
    "# Create the final pipeline with the preprocessor and your model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=230, random_state=1))\n",
    "])\n",
    "\n",
    "def cv(my_pipeline):\n",
    "    scores = -1 * cross_val_score(my_pipeline, df, log_y,\n",
    "                                  cv=5,\n",
    "                                  scoring='neg_mean_squared_error')\n",
    "    return np.mean(np.sqrt(scores))\n",
    "\n",
    "print(f'The RMSLE in SalePrice is : \\n{cv(pipeline)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "First, I will now look at a few linear regression models (including regularised models such as Ridge and Lasso), running a grid search on their parameters.\n",
    "\n",
    "I will then go onto train ensemble models, such as Random Forest, XGBoost.\n",
    "\n",
    "I first looked at implementing the hyperparameterisation with Optuna, but decided this was unnecessariily complex and made my code unreadable. I have gone back to using simple GridSearchCV\n",
    "\n",
    "There may be a way to integrate this individual model search\n",
    "    into GridSearchCV however because each modle has a different param\n",
    "    set I proceeded this way to make it simpler\n",
    "\n",
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(model, params, tracker):\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    gs= GridSearchCV(pipeline,\n",
    "                    param_grid=params,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    cv=5,\n",
    "                    verbose=1\n",
    "                )\n",
    "    \n",
    "    gs.fit(df,log_y);\n",
    "\n",
    "    scores = np.array([-1*gs.cv_results_[f'split{i}_test_score'] for i in range(gs.n_splits_)])\n",
    "    best_RMSLE = min(np.mean(np.sqrt(scores),axis=1))\n",
    "\n",
    "    # mean_score = -1 * gs.cv_results_['mean_test_score']\n",
    "    # print(mean_score)\n",
    "    # best_RMSLE = np.sqrt(max(mean_score))\n",
    "    \n",
    "    tracker[str(model)] = best_RMSLE\n",
    "    \n",
    "    print(f'For {str(model)}, optimal param when {gs.best_params_} with score RMSLE: \\n{best_RMSLE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "For Ridge(alpha=0.0001), optimal param when {'model__alpha': 0.00099} with score RMSLE: \n",
      "0.12746488202135894\n"
     ]
    }
   ],
   "source": [
    "tracker = {}\n",
    "\n",
    "model = Ridge(alpha=0.0001)\n",
    "params = {'model__alpha' : list(np.arange(0.0001,0.001,0.00001))}\n",
    "run_search(model,params,tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "For Lasso(alpha=0.0001), optimal param when {'model__alpha': 0.0002} with score RMSLE: \n",
      "0.1288422796986309\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(alpha=0.0001)\n",
    "params = {'model__alpha' : list(np.arange(0.0001,0.001,0.0001))}\n",
    "run_search(model,params,tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "For ElasticNet(alpha=0.0001, l1_ratio=1.0), optimal param when {'model__alpha': 0.00025, 'model__l1_ratio': 1.0} with score RMSLE: \n",
      "0.12860559103205352\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet(alpha=0.0001, l1_ratio=1.0)\n",
    "params = {'model__alpha' : list(np.arange(0.0001,0.001,0.00001)),\n",
    "          'model__l1_ratio': [1.0, 0.9, 0.8, 0.7]}\n",
    "run_search(model,params,tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge(alpha=0.0001)': 0.14309157278757242,\n",
       " 'Lasso(alpha=0.0001)': 0.14137669551618348,\n",
       " 'ElasticNet(alpha=0.0001, l1_ratio=1.0)': 0.1412910490555424}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "For RandomForestRegressor(), optimal param when {'model__n_estimators': 200, 'model__random_state': 1} with score RMSLE: \n",
      "0.13697396633072143\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "params = {'model__n_estimators': range(30,300,10),\n",
    "          'model__random_state': [1]}\n",
    "run_search(model,params,tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge(alpha=0.0001)': 0.12746488202135894,\n",
       " 'Lasso(alpha=0.0001)': 0.1288422796986309,\n",
       " 'ElasticNet(alpha=0.0001, l1_ratio=1.0)': 0.12860559103205352,\n",
       " 'RandomForestRegressor()': 0.13697396633072143}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "params = {'mdoel__':\n",
    "          }\n",
    "run_search(model,params,tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor()'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
